{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify Project Workspace\n",
    "This workspace contains a tiny subset (128MB) of the full dataset available (12GB). Feel free to use this workspace to build your project, or to explore a smaller subset with Spark before deploying your cluster on the cloud. Instructions for setting up your Spark cluster is included in the last lesson of the Extracurricular Spark Course content.\n",
    "\n",
    "You can follow the steps below to guide your data analysis and model building portion of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:04:27.254246Z",
     "start_time": "2020-03-22T19:04:27.220794Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import min as smin, max as smax, sum as ssum, round as sround\n",
    "from pyspark.sql.functions import isnan, isnull, when, first, avg, last, count, countDistinct, col, lag, lead, coalesce, lit, split, trim\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import to_date, date_format, from_unixtime, to_timestamp\n",
    "\n",
    "from pyspark.sql.types import DateType, TimestampType, IntegerType\n",
    " \n",
    "import jupyter_utils as j\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    " \n",
    "SparkContext.setSystemProperty('spark.logConf', 'True')\n",
    "SparkContext.setSystemProperty('spark.default.parallelism', '16')\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '4g')\n",
    "SparkContext.setSystemProperty('spark.driver.memory', '8g')\n",
    "SparkContext.setSystemProperty('spark.reducer.maxSizeInFlight', '96m')\n",
    "SparkContext.setSystemProperty('spark.shuffle.consolidateFiles', 'True') \n",
    "SparkContext.setSystemProperty('spark.shuffle.service.index.cache.size', '500m')\n",
    "\n",
    "SparkContext.setSystemProperty('spark.driver.extraJavaOptions', '-server -Xmx8G')\n",
    "SparkContext.setSystemProperty('spark.executor.extraJavaOptions', '-server -Xmx8G -XX:+UseG1GC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:25.051955Z",
     "start_time": "2020-03-22T16:05:25.045700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "j.reload(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:26.536664Z",
     "start_time": "2020-03-22T16:05:26.533303Z"
    }
   },
   "outputs": [],
   "source": [
    "# filepath = 'sparkify_full_csv_data.csv'\n",
    "filepath = 'medium_sparkify_event_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:29.113624Z",
     "start_time": "2020-03-22T16:05:27.956182Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:32.327260Z",
     "start_time": "2020-03-22T16:05:32.292959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.executor.memory', '4g'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.id', 'local-1584893128494'),\n",
       " ('spark.driver.port', '43275'),\n",
       " ('spark.shuffle.service.index.cache.size', '500m'),\n",
       " ('spark.reducer.maxSizeInFlight', '96m'),\n",
       " ('spark.shuffle.consolidateFiles', 'True'),\n",
       " ('spark.default.parallelism', '16'),\n",
       " ('spark.logConf', 'True'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.memory', '8g'),\n",
       " ('spark.app.name', 'Sparkify'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.host', '192.168.0.107')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Dataset\n",
    "In this workspace, the mini-dataset file is `mini_sparkify_event_data.json`. Load and clean the dataset, checking for invalid or missing data - for example, records without userids or sessionids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:38.952816Z",
     "start_time": "2020-03-22T16:05:36.067717Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").option(\"encoding\", \"utf-8\").csv(filepath)\n",
    "df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").option(\"encoding\", \"utf-8\").json(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T03:04:47.098475Z",
     "start_time": "2020-03-22T03:04:47.036600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized 1x Replicated\n",
      "Memory Serialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "from pyspark import StorageLevel\n",
    "\n",
    "print(df.storageLevel)\n",
    "\n",
    "df.persist(StorageLevel.MEMORY_ONLY)\n",
    "\n",
    "print(df.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T20:47:53.568936Z",
     "start_time": "2020-03-21T20:47:53.551739Z"
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:44:23.082123Z",
     "start_time": "2020-03-14T21:44:22.438015Z"
    }
   },
   "outputs": [],
   "source": [
    "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:46:58.898921Z",
     "start_time": "2020-03-14T21:46:58.481407Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('auth').agg(count(col('auth'))).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T22:13:17.244523Z",
     "start_time": "2020-03-14T22:13:17.152911Z"
    }
   },
   "outputs": [],
   "source": [
    "df.where(~df.auth.isin(['Logged In', 'Cancelled'])).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T22:03:26.627411Z",
     "start_time": "2020-03-14T22:03:26.549337Z"
    }
   },
   "outputs": [],
   "source": [
    "df.where((df.auth == 'Logged In') & (df.page == 'Home')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:42.968031Z",
     "start_time": "2020-03-22T16:05:42.954800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger instance created\n"
     ]
    }
   ],
   "source": [
    "log4jLogger = spark.sparkContext._jvm.org.apache.log4j\n",
    "\n",
    "LOGGER = log4jLogger.LogManager.getLogger('driver_logger')\n",
    "\n",
    "def info(message, print_on_notebook = True):\n",
    "    LOGGER.info(message)\n",
    "    \n",
    "    if print_on_notebook:\n",
    "        print(message)\n",
    "    \n",
    "info('Logger instance created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:44.684907Z",
     "start_time": "2020-03-22T16:05:44.669208Z"
    }
   },
   "outputs": [],
   "source": [
    "CHURN_CANCELLATION_PAGE = 'Cancellation Confirmation'\n",
    "REGISTRATION_PAGE = 'Submit Registration'\n",
    "milliseconds_to_hours = 3600 * 1000\n",
    "minutes_to_hours = 60 * 60\n",
    "TRUE = 1\n",
    "FALSE = 0\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \n",
    "    info('Starting data cleaning...')\n",
    "    \n",
    "    total_before = df.count()\n",
    "    \n",
    "    # Keep only logged records\n",
    "    df = df.where(df.auth.isin(['Logged In', 'Cancelled']))\n",
    "    \n",
    "    # Records without userId\n",
    "    df = df.where(col('userId').isNotNull())\n",
    "    \n",
    "    # Create a date column for the event\n",
    "    df = df.withColumn('date', from_unixtime(col('ts') / 1000).cast(DateType()))\n",
    "    \n",
    "    # Location\n",
    "    # df = df.withColumn('state', trim(split((split('location', ',').getItem(1)), '-').getItem(0)))\n",
    "    \n",
    "    # Relevant windows\n",
    "    w_session = Window.partitionBy('sessionId').orderBy('ts')\n",
    "    w_user_session = Window.partitionBy('sessionId', 'userId').orderBy('ts').rangeBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "    w_user = Window.partitionBy('userId').orderBy('ts').rangeBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "    \n",
    "    # Create features\n",
    "    df = df.withColumn('previous_page', lag(df.page).over(w_session))\n",
    "    df = df.withColumn('last_event_ts', last(col('ts')).over(w_user))\n",
    "    df = df.withColumn('last_page', last(col('page')).over(w_user))\n",
    "    df = df.withColumn('register_page', first(col('previous_page')).over(w_user))\n",
    "    df = df.withColumn('first_ts', first(col('ts')).over(w_user))\n",
    "    df = df.withColumn('ts_elapsed', last(df.ts).over(w_session) - first(df.ts).over(w_user_session))\n",
    "    df = df.withColumn('session_duration', smax(df.ts_elapsed).over(w_user_session))\n",
    "     \n",
    "    info('Finished data cleaning...')\n",
    "    info(f'Number of removed rows: {total_before - df.count()}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:49.117224Z",
     "start_time": "2020-03-22T16:05:47.549600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data cleaning...\n",
      "Finished data cleaning...\n",
      "Number of removed rows: 15700\n"
     ]
    }
   ],
   "source": [
    "df = clean_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "When you're working with the full dataset, perform EDA by loading a small subset of the data and doing basic manipulations within Spark. In this workspace, you are already provided a small subset of data you can explore.\n",
    "\n",
    "### Define Churn\n",
    "\n",
    "Once you've done some preliminary analysis, create a column `Churn` to use as the label for your model. I suggest using the `Cancellation Confirmation` events to define your churn, which happen for both paid and free users. As a bonus task, you can also look into the `Downgrade` events.\n",
    "\n",
    "### Explore Data\n",
    "Once you've defined churn, perform some exploratory data analysis to observe the behavior for users who stayed vs users who churned. You can start by exploring aggregates on these two groups of users, observing how much of a specific action they experienced per a certain time unit or number of songs played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T18:30:01.910759Z",
     "start_time": "2020-03-08T18:30:01.480161Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupBy('page').count().orderBy('count', ascending = False).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions about the data:\n",
    "\n",
    "- Are errors related to downgrading canceling the service?\n",
    "- Having a certain number of friends or a sense of community can decrease the churn?\n",
    "- Thumbs down are related to churn? (could the quality of the songs catalog affect the churn)\n",
    "- The advertising is not annoying the users?\n",
    "- Users with stay connected for more time have less change to churn?\n",
    "- Is the home page relevant?\n",
    "- Users, who access the downgrade page are how much more willing to churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T18:30:06.259628Z",
     "start_time": "2020-03-08T18:30:05.841058Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupBy('status').count().orderBy('count', ascending = False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T22:44:01.657485Z",
     "start_time": "2020-03-01T22:44:01.094695Z"
    }
   },
   "outputs": [],
   "source": [
    "df.filter('userId = 92').groupBy('page').count().orderBy('count', ascending = False).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T18:30:16.616860Z",
     "start_time": "2020-03-08T18:30:16.073824Z"
    }
   },
   "outputs": [],
   "source": [
    "df.filter('userId = 92').groupBy('page').count().orderBy('count', ascending = False).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T18:30:29.650593Z",
     "start_time": "2020-03-08T18:30:29.435808Z"
    }
   },
   "outputs": [],
   "source": [
    "df.filter('userId = 92').groupBy('userAgent').count().orderBy('count', ascending = False).show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T18:30:37.323100Z",
     "start_time": "2020-03-08T18:30:36.828209Z"
    }
   },
   "outputs": [],
   "source": [
    "df.filter('userId = 92 and song != \\'null\\' ').groupBy('song').count().orderBy('count', ascending = False).show(50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Once you've familiarized yourself with the data, build out the features you find promising to train your model on. To work with the full dataset, you can follow the following steps.\n",
    "- Write a script to extract the necessary features from the smaller subset of data\n",
    "- Ensure that your script is scalable, using the best practices discussed in Lesson 3\n",
    "- Try your script on the full data set, debugging your script if necessary\n",
    "\n",
    "If you are working in the classroom workspace, you can just extract features based on the small subset of data contained here. Be sure to transfer over this work to the larger dataset when you work on your Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:54.142199Z",
     "start_time": "2020-03-22T16:05:54.108627Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_session_dimension(df):\n",
    "    \n",
    "    # sessions from the user\n",
    "    df_sessions = df.orderBy(df.sessionId).groupBy('sessionId', 'userId').agg(\n",
    "        smax(df.ts).alias('max_event_ts'),\n",
    "        smin(df.ts).alias('min_event_ts'),\n",
    "        ssum(df.length).alias('session_n_total_playback'), # Based on songs length\n",
    "        count(when(df.page == 'Thumbs Up', True)).alias(\"session_n_likes\"),\n",
    "        count(when(df.page == 'Thumbs Down', True)).alias(\"session_n_dislikes\"),\n",
    "        count(when(df.page == 'NextSong', True)).alias(\"session_n_songs\"),\n",
    "        count(when(df.page == 'Add Friend', True)).alias(\"session_n_friends\"),\n",
    "        count(when(df.page == 'Add to Playlist', True)).alias(\"session_n_add_playlist\"),\n",
    "        count(when(df.page == 'Home', True)).alias(\"session_n_home\"),\n",
    "        count(when(df.page == 'Roll Advert', True)).alias(\"session_n_ads\"),\n",
    "        count(when(df.page == 'Help', True)).alias(\"session_n_help\"),\n",
    "        count(when(df.page == 'Error', True)).alias(\"session_n_error\"),\n",
    "        count(when(df.page == 'Settings', True)).alias(\"session_n_sets\"),\n",
    "        count(col('page')).alias('session_n_actions'),\n",
    "        first(col('session_duration')).alias('session_duration')\n",
    "    ) \n",
    "    \n",
    "    # Calculate the interval until the next session\n",
    "    w_user_sessions_interval = Window.partitionBy('userId').orderBy('min_event_ts')\n",
    "    df_sessions = df_sessions.withColumn('interval_to_session', col('min_event_ts') - lag(col('max_event_ts')).over(w_user_sessions_interval))\n",
    "    \n",
    "    # Calculate average time in hours for each session\n",
    "    df_session_time = df_sessions.groupBy('userId').agg(\n",
    "       (avg(df_sessions.session_duration) / milliseconds_to_hours).alias('session_hours')\n",
    "    )\n",
    "    df_sessions = df_sessions.join(df_session_time, on = 'userId')\n",
    "    \n",
    "    # We should remove the null lines before count/group to not account 2 times the mean interval\n",
    "    df_sessions = df_sessions.groupBy('userId').agg(  \n",
    "        (avg(df_sessions.interval_to_session) / milliseconds_to_hours).alias('session_avg_time_away'),\n",
    "        ((avg(df_sessions.session_n_total_playback) / minutes_to_hours) / first(col('session_hours'))).alias('session_avg_playback'), \n",
    "        (avg(df_sessions.session_n_likes) / first(col('session_hours'))).alias('session_avg_likes'),\n",
    "        (avg(df_sessions.session_n_dislikes) / first(col('session_hours'))).alias('session_avg_dislikes'),\n",
    "        (avg(df_sessions.session_n_songs) / first(col('session_hours'))).alias('session_avg_songs'),\n",
    "        (avg(df_sessions.session_n_friends) / first(col('session_hours'))).alias('session_avg_friends'),\n",
    "        (avg(df_sessions.session_n_add_playlist) / first(col('session_hours'))).alias('session_avg_added_playlist'),\n",
    "        (avg(df_sessions.session_n_home) / first(col('session_hours'))).alias('session_avg_home'),\n",
    "        (avg(df_sessions.session_n_ads) / first(col('session_hours'))).alias('session_avg_ads'),\n",
    "        (avg(df_sessions.session_n_help) / first(col('session_hours'))).alias('session_avg_help'),\n",
    "        (avg(df_sessions.session_n_error) / first(col('session_hours'))).alias('session_avg_errors'),\n",
    "        (avg(df_sessions.session_n_sets) / first(col('session_hours'))).alias('session_avg_settings'),\n",
    "        (avg(df_sessions.session_n_actions) / first(col('session_hours'))).alias('session_avg_actions')\n",
    "    )\n",
    "    \n",
    "    return df_sessions\n",
    "\n",
    "def create_user_dimension(df):\n",
    "    \n",
    "    df_user_profile = df.groupby('userId')\\\n",
    "        .agg( \n",
    "\n",
    "            # first(col('state')).alias('state'),\n",
    "            first(when(col('gender') == 'M', TRUE).otherwise(FALSE)).alias('male'),\n",
    "\n",
    "            smin(col('first_ts')).alias('ts_start'),\n",
    "            smax(col('last_event_ts')).alias('ts_end'),        \n",
    "        \n",
    "            ((smax(col('last_event_ts')) - smin(col('first_ts'))) / milliseconds_to_hours).alias('time_window'),\n",
    "        \n",
    "            # Subscription\n",
    "            count(when(col('page') == 'Submit Downgrade', True)).alias('n_downgrades'),\n",
    "            count(when(col('page') == 'Submit Upgrade', True)).alias('n_upgrades'),\n",
    "            last(when(col('level') == 'paid', TRUE).otherwise(FALSE)).alias('paid'),\n",
    "            first(when(col('last_page') == CHURN_CANCELLATION_PAGE, TRUE).otherwise(FALSE)).alias('canceled'),\n",
    "\n",
    "            # Streaming\n",
    "            count(when(col('page') == 'NextSong', True)).alias('n_songs'),\n",
    "            count(when(col('page') == 'Thumbs Up', True)).alias('n_likes'),\n",
    "            count(when(col('page') == 'Thumbs Down', True)).alias('n_dislikes'),\n",
    "            countDistinct(col('sessionId')).alias('n_sess'),\n",
    "            (avg(col('session_duration')) / milliseconds_to_hours).alias('avg_session_duration'),\n",
    "\n",
    "            # Community\n",
    "            count(when(col('page') == 'Add Friend', True)).alias('n_friends'),\n",
    "            count(when(col('page') == 'Add to Playlist', True)).alias('n_added_to_playlist'),\n",
    "\n",
    "            # Other\n",
    "            count(when(col('page') == 'Home', True)).alias('n_home'),\n",
    "            count(when(col('page') == 'Roll Advert', True)).alias('n_ads'),\n",
    "            count(when(col('page') == 'Help', True)).alias('n_help'),\n",
    "            count(when(col('page') == 'Error', True)).alias('n_errors'),\n",
    "            count(when(col('page') == 'Settings', True)).alias('n_settings'),\n",
    "            count(col('page')).alias('n_actions')\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Location\n",
    "    # states = list(map(lambda c: c[0].strip(), df.select(['state']).distinct().rdd.collect()))\n",
    "    # for state in states:\n",
    "    #    df_user_profile = df_user_profile.withColumn(state.lower(), when(df_user_profile.state == state, 1).otherwise(0))\n",
    "    \n",
    "    return df_user_profile\n",
    "\n",
    "def create_days_dimension(df):\n",
    "    \n",
    "    df_unique_days = df.groupby('userId').agg(countDistinct('date').alias('n_days'))\n",
    "    \n",
    "    df_daily_actions = df.groupby('userId', 'date').agg(count('page').alias('total'))\n",
    "    df_daily_actions = df_daily_actions.groupby('userId').agg(avg('total').alias('avg_daily_actions')) \n",
    "\n",
    "    df_days = df_unique_days.join(df_daily_actions, df_unique_days.userId == df_daily_actions.userId)\n",
    "    \n",
    "    # Remove duplicated column after join\n",
    "    df_days = df_days.drop(df_daily_actions.userId)\n",
    "    \n",
    "    return df_days\n",
    "\n",
    "def sort_features(df, columns_order):\n",
    "    _columns = df.columns\n",
    "    _columns.sort()\n",
    "    \n",
    "    for _idx, _val in list(enumerate(columns_order)):\n",
    "        _columns.pop(_columns.index(_val))\n",
    "        _columns.insert(_idx, _val)\n",
    "        \n",
    "    assert len(_columns) == len(df.columns)\n",
    "\n",
    "    return _columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:05:58.588822Z",
     "start_time": "2020-03-22T16:05:57.828003Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sessions = create_session_dimension(df)\n",
    "df_days = create_days_dimension(df)\n",
    "\n",
    "df_users = create_user_dimension(df)\n",
    "df_users = df_users.orderBy(df_users.userId).join(df_days, on = 'userId')\n",
    "\n",
    "_columns = sort_features(df_users, [ 'userId', 'male', 'paid', 'canceled'])\n",
    "_columns = list(set(df_users.schema.names + df_sessions.schema.names) - set(['ts_start', 'ts_end', 'state']))\n",
    "\n",
    "df_users = df_users.orderBy(df_users.userId).join(df_sessions, on = 'userId').select(_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T20:48:42.386121Z",
     "start_time": "2020-03-21T20:48:42.376902Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T20:49:03.344898Z",
     "start_time": "2020-03-21T20:48:49.766564Z"
    }
   },
   "outputs": [],
   "source": [
    "### WARN: Only round to display\n",
    "# Enforces the order for some columns\n",
    "df_users.select([sround(c, 0).cast(dataType = IntegerType()).alias(c) for c in _columns]).fillna(0).show(2, True, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T20:49:25.483187Z",
     "start_time": "2020-03-21T20:49:15.575158Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users.select(_columns).fillna(0).toPandas().to_csv('sparkify_data_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T20:49:53.790091Z",
     "start_time": "2020-03-21T20:49:53.293466Z"
    }
   },
   "outputs": [],
   "source": [
    "df.agg(countDistinct(df.userId).alias('unique_users')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.orderBy(df_users.userId).join(df_sessions, on = 'userId').select(_columns).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.orderBy(df_users.userId).join(df_sessions, on = 'userId').select(_columns).groupBy('canceled').agg(count(df_users.canceled).alias('total')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Advertises number (per session and all)\n",
    "    - The user **100010** returned after some idle time and received a considerable amount of advertises;\n",
    "    - Also, after thumbs down, I received two advertisements on four sounds. Then canceled the service.\n",
    "- Number of sessions\n",
    "- Paid subscription time\n",
    "- Avg songs before an ad\n",
    "- Number of skipped songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_date(df.ts.cast(dataType=TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df.userId == user_id).select(['artist',\n",
    " 'auth',\n",
    " 'firstName',\n",
    " 'gender',\n",
    " 'itemInSession',\n",
    " 'lastName',\n",
    " 'length',\n",
    " 'level', \n",
    " 'page',\n",
    " 'sessionId',\n",
    " 'song', \n",
    " 'ts', \n",
    " 'userId']).orderBy('sessionId', 'itemInSession').withColumn('datetime', date_format((df.ts/1000).cast(dataType=TimestampType()), 'HH:mm:ss dd-MM-YYYY')).show(350, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Split the full dataset into train, test, and validation sets. Test out several of the machine learning methods you learned. Evaluate the accuracy of the various models, tuning parameters as necessary. Determine your winning model based on test accuracy and report results on the validation set. Since the churned users are a fairly small subset, I suggest using F1 score as the metric to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:08.503587Z",
     "start_time": "2020-03-22T16:06:08.499710Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T15:01:34.745712Z",
     "start_time": "2020-03-01T15:01:34.737694Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_exclude = set(['userId'])\n",
    "\n",
    "columns_to_use = list(set(df_users.columns) - columns_to_exclude)\n",
    "\n",
    "columns_to_train = list(set(columns_to_use) - set(['canc']))\n",
    "\n",
    "columns_to_use.sort()\n",
    "columns_to_train.sort()\n",
    "\n",
    "print(f'Columns: {columns_to_use}\\n')\n",
    "print(f'Columns to train: {columns_to_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:11.343476Z",
     "start_time": "2020-03-22T16:06:11.339744Z"
    }
   },
   "outputs": [],
   "source": [
    "CHURN_LABEL = 'canceled'\n",
    "TRAIN_SPLIT_RATIO = .7\n",
    "TEST_SPLIT_RATIO = .3\n",
    "\n",
    "SPLIT_RATIO = [TRAIN_SPLIT_RATIO, TEST_SPLIT_RATIO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:12.939628Z",
     "start_time": "2020-03-22T16:06:12.923671Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_features = [ 'paid', 'male' ]\n",
    "\n",
    "numeric_features = [\n",
    "    'avg_daily_actions',\n",
    "    'avg_session_duration', \n",
    "    'n_actions',\n",
    "    'n_added_to_playlist',\n",
    "    'n_ads',\n",
    "    'n_days',\n",
    "    'n_dislikes',\n",
    "    'n_downgrades',\n",
    "    'n_errors',\n",
    "    'n_friends',\n",
    "    'n_help',\n",
    "    'n_home',\n",
    "    'n_likes',\n",
    "    'n_sess',\n",
    "    'n_settings',\n",
    "    'n_songs',\n",
    "    'n_upgrades', \n",
    "    'session_avg_actions',\n",
    "    'session_avg_added_playlist',\n",
    "    'session_avg_ads',\n",
    "    'session_avg_dislikes',\n",
    "    'session_avg_errors',\n",
    "    'session_avg_friends',\n",
    "    'session_avg_help',\n",
    "    'session_avg_home',\n",
    "    'session_avg_likes',\n",
    "    'session_avg_playback',\n",
    "    'session_avg_settings',\n",
    "    'session_avg_songs',\n",
    "    'session_avg_time_away',\n",
    "    'time_window'\n",
    "]\n",
    "\n",
    "columns_all = [\n",
    "    'canceled',\n",
    "    'male',\n",
    "    'paid',\n",
    "    'avg_daily_actions',\n",
    "    'avg_session_duration', \n",
    "    'n_actions',\n",
    "    'n_added_to_playlist',\n",
    "    'n_ads',\n",
    "    'n_days',\n",
    "    'n_dislikes',\n",
    "    'n_downgrades',\n",
    "    'n_errors',\n",
    "    'n_friends',\n",
    "    'n_help',\n",
    "    'n_home',\n",
    "    'n_likes',\n",
    "    'n_sess',\n",
    "    'n_settings',\n",
    "    'n_songs',\n",
    "    'n_upgrades', \n",
    "    'session_avg_actions',\n",
    "    'session_avg_added_playlist',\n",
    "    'session_avg_ads',\n",
    "    'session_avg_dislikes',\n",
    "    'session_avg_errors',\n",
    "    'session_avg_friends',\n",
    "    'session_avg_help',\n",
    "    'session_avg_home',\n",
    "    'session_avg_likes',\n",
    "    'session_avg_playback',\n",
    "    'session_avg_settings',\n",
    "    'session_avg_songs',\n",
    "    'session_avg_time_away',\n",
    "    'time_window'\n",
    "]\n",
    "\n",
    "columns_to_train = [\n",
    "    'male',\n",
    "    'paid',\n",
    "    'avg_daily_actions',\n",
    "    'avg_session_duration', \n",
    "    'n_actions',\n",
    "    'n_added_to_playlist',\n",
    "    'n_ads',\n",
    "    'n_days',\n",
    "    'n_dislikes',\n",
    "    'n_downgrades',\n",
    "    'n_errors',\n",
    "    'n_friends',\n",
    "    'n_help',\n",
    "    'n_home',\n",
    "    'n_likes',\n",
    "    'n_sess',\n",
    "    'n_settings',\n",
    "    'n_songs',\n",
    "    'n_upgrades', \n",
    "    'session_avg_actions',\n",
    "    'session_avg_added_playlist',\n",
    "    'session_avg_ads',\n",
    "    'session_avg_dislikes',\n",
    "    'session_avg_errors',\n",
    "    'session_avg_friends',\n",
    "    'session_avg_help',\n",
    "    'session_avg_home',\n",
    "    'session_avg_likes',\n",
    "    'session_avg_playback',\n",
    "    'session_avg_settings',\n",
    "    'session_avg_songs',\n",
    "    'session_avg_time_away',\n",
    "    'time_window'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:16.342291Z",
     "start_time": "2020-03-22T16:06:16.324170Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_multiclass_classifier(predictions, columns):\n",
    "    metrics_to_evaluate = [ 'accuracy', 'f1', 'weightedPrecision', 'weightedRecall' ]\n",
    "    \n",
    "    result = {}\n",
    "    for metric in metrics_to_evaluate:\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol = columns[0], predictionCol = columns[1], metricName = metric)\n",
    "        value = evaluator.evaluate(predictions)\n",
    "        result[metric] = value\n",
    "        print(f'{metric}: {value}') \n",
    "    \n",
    "    return result\n",
    "\n",
    "def train_random_forest_classifier(data, columns, train_cloumns):\n",
    "    \n",
    "    # Split train/test\n",
    "    (train_df, test_df) = data.randomSplit(SPLIT_RATIO, seed = 42)\n",
    "    \n",
    "    # Create the indexer for labels\n",
    "    l_indexer = StringIndexer(inputCol = CHURN_LABEL, outputCol = 'idx_labels')\n",
    "    f_binaries = VectorAssembler(inputCols = binary_features, outputCol = 'bin_features')\n",
    "    f_numeric = VectorAssembler(inputCols = numeric_features, outputCol = 'num_features')\n",
    "    \n",
    "    f_scaler = StandardScaler(inputCol = 'num_features', outputCol = 'num_features_escaled', withStd = True, withMean = True)\n",
    "    \n",
    "    f_all = VectorAssembler(inputCols = [ 'bin_features' , 'num_features_escaled' ], outputCol = 'features')\n",
    "    \n",
    "    l_translator = IndexToString(inputCol = 'prediction', outputCol = 'predictedLabel', labels = [ 'Not churn', 'Churn' ])\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(labelCol = 'idx_labels', featuresCol = 'features', numTrees = 10, maxBins = 5, impurity = 'entropy', minInstancesPerNode = 3, seed = 42)\n",
    "    \n",
    "    pipeline = Pipeline(stages = [ l_indexer, f_binaries, f_numeric, f_scaler, f_all, rf_classifier, l_translator ])\n",
    "    \n",
    "    # Train the model\n",
    "    model = pipeline.fit(train_df)\n",
    "\n",
    "    # Test the model\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    return model.stages[2], predictions\n",
    "    \n",
    "\n",
    "def create_pipeline(model):\n",
    "    \n",
    "    l_indexer = StringIndexer(inputCol = CHURN_LABEL, outputCol = 'idx_labels')\n",
    "    f_binaries = VectorAssembler(inputCols = binary_features, outputCol = 'bin_features')\n",
    "    f_numeric = VectorAssembler(inputCols = numeric_features, outputCol = 'num_features')\n",
    "    f_scaler = StandardScaler(inputCol = 'num_features', outputCol = 'num_features_escaled', withStd = True, withMean = True)\n",
    "    f_all = VectorAssembler(inputCols = [ 'bin_features' , 'num_features_escaled' ], outputCol = 'features')\n",
    "    pipeline = Pipeline(stages = [ l_indexer, f_binaries, f_numeric, f_scaler, f_all, model ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def create_random_forest_pipeline():\n",
    "    rf_classifier = RandomForestClassifier(labelCol = 'canceled', featuresCol = 'features', seed = 42)\n",
    "    return create_pipeline(rf_classifier)\n",
    "\n",
    "def create_gradient_boost_pipeline():\n",
    "    gbt_classifier = GBTClassifier(labelCol = 'canceled', maxDepth = 5, maxIter = 100)\n",
    "    return create_pipeline(gbt_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:19.707388Z",
     "start_time": "2020-03-22T16:06:19.555369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the new dataframe\n",
    "df_users = df_users.select(columns_all).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:07:01.999691Z",
     "start_time": "2020-03-21T21:06:53.158970Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:14:23.154867Z",
     "start_time": "2020-03-21T23:13:27.220280Z"
    }
   },
   "outputs": [],
   "source": [
    "model, predictions = train_random_forest_classifier(df_users, columns_all, columns_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:15:33.676310Z",
     "start_time": "2020-03-21T23:14:48.782886Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_multiclass_classifier(predictions, ('canceled', 'prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:15:59.264578Z",
     "start_time": "2020-03-21T23:15:49.342154Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results = predictions.select(['canceled', 'prediction', 'predictedLabel']).toPandas()\n",
    "df_results['prediction'] = df_results.prediction.apply(int)\n",
    "plot_confusion_matrix(df_results['canceled'], df_results['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:54:56.121279Z",
     "start_time": "2020-03-21T21:54:56.113194Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_results['canceled'], df_results['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:38:50.323684Z",
     "start_time": "2020-03-21T21:38:50.316950Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_results['canceled'], df_results['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:28.430496Z",
     "start_time": "2020-03-22T16:06:28.123336Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T21:38:39.228859Z",
     "start_time": "2020-03-21T21:38:39.213960Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:29.935043Z",
     "start_time": "2020-03-22T16:06:29.931336Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# plot_confusion_matrix(df_results['canceled'], df_results['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:31.779969Z",
     "start_time": "2020-03-22T16:06:31.771211Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_predictions):\n",
    "    \n",
    "    # auc = roc_auc_score(y_test, y_predictions)\n",
    "    cm = confusion_matrix(y_test, y_predictions, labels = [1, 0])\n",
    "    \n",
    "    tn = cm[0, 0]\n",
    "    tp = cm[1, 1]\n",
    "    fn = cm[1, 0]\n",
    "    fp = cm[0, 1]\n",
    "    \n",
    "    total = np.sum(cm) # tn + tp + fn + fp\n",
    "    accuracy = (tp + tn) / total\n",
    "    precision = (tp) / (tp + fp)\n",
    "    recall = (tp) / (tp + fn) \n",
    "    \n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T21:27:07.966315Z",
     "start_time": "2020-02-29T21:26:10.470241Z"
    }
   },
   "outputs": [],
   "source": [
    "model, predictions = train_random_forest_classifier(df_users, columns_to_use, columns_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T21:49:02.428480Z",
     "start_time": "2020-02-29T21:47:25.148792Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_multiclass_classifier(predictions, ('canc', 'prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T21:49:40.743405Z",
     "start_time": "2020-02-29T21:49:22.720697Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol = 'canc', metricName = 'areaUnderROC')\n",
    "\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxBins = 5, impurity = 'entropy', minInstancesPerNode = 3, seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T02:56:27.866180Z",
     "start_time": "2020-03-22T02:56:27.860716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 10, 15, 20, 25, 30, 35, 40]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5, 45, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:37.687392Z",
     "start_time": "2020-03-22T16:06:37.659696Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "def create_grid_search(pipeline, param_grid, evaluator = MulticlassClassificationEvaluator(labelCol = 'canceled', metricName = 'f1')):\n",
    "    \n",
    "    return CrossValidator(estimator = pipeline, estimatorParamMaps = param_grid, evaluator = evaluator, numFolds = 2, parallelism = 12)\n",
    "\n",
    "def random_forest_grid_search(pipeline):\n",
    "    \n",
    "    model = pipeline.getStages()[-1]\n",
    "\n",
    "    grid_rf = ParamGridBuilder().addGrid(model.maxDepth, [5, 10, 15, 20, 25]) \n",
    "    grid_rf = grid_rf.addGrid(model.impurity, ['gini']) \n",
    "    grid_rf = grid_rf.addGrid(model.maxBins, [5, 10, 15, 20, 25, 30, 35, 40])\n",
    "    grid_rf = grid_rf.addGrid(model.numTrees, [10, 20, 40, 60, 70])\n",
    "    grid_rf = grid_rf.build()\n",
    "    \n",
    "    print(f'Number of models to train: {len(grid_rf)}')\n",
    "        \n",
    "    return create_grid_search(pipeline, grid_rf)\n",
    "\n",
    "def gradient_boost_grid_search(pipeline):\n",
    "    \n",
    "    model = pipeline.getStages()[-1]\n",
    "\n",
    "    grid_gbt = ParamGridBuilder().addGrid(model.maxDepth, [5]) #, 10, 15, 20, 25])\n",
    "    grid_gbt = grid_gbt.addGrid(model.maxIter, [20])#, 25, 40, 50, 100])\n",
    "    grid_gbt = grid_gbt.build()\n",
    "   \n",
    "    return create_grid_search(pipeline, grid_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:06:41.243473Z",
     "start_time": "2020-03-22T16:06:41.212313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the new dataframe\n",
    "# data = df_users.select(columns_to_use).fillna(0)\n",
    "\n",
    "# Split train/test\n",
    "(train_df, test_df) = df_users.randomSplit(SPLIT_RATIO, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:48:02.519957Z",
     "start_time": "2020-03-22T16:06:46.868617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to train: 200\n"
     ]
    }
   ],
   "source": [
    "pipeline = create_random_forest_pipeline()\n",
    "cv_rf = random_forest_grid_search(pipeline)\n",
    "cv_rf_results = cv_rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:14:24.547347Z",
     "start_time": "2020-03-22T19:14:24.538041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__metaclass__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_clear',\n",
       " '_copyValues',\n",
       " '_copy_params',\n",
       " '_defaultParamMap',\n",
       " '_dummy',\n",
       " '_from_java',\n",
       " '_from_java_impl',\n",
       " '_paramMap',\n",
       " '_params',\n",
       " '_randomUID',\n",
       " '_resetUid',\n",
       " '_resolveParam',\n",
       " '_set',\n",
       " '_setDefault',\n",
       " '_shouldOwn',\n",
       " '_to_java',\n",
       " '_to_java_impl',\n",
       " '_transform',\n",
       " 'avgMetrics',\n",
       " 'bestModel',\n",
       " 'copy',\n",
       " 'estimator',\n",
       " 'estimatorParamMaps',\n",
       " 'evaluator',\n",
       " 'explainParam',\n",
       " 'explainParams',\n",
       " 'extractParamMap',\n",
       " 'getEstimator',\n",
       " 'getEstimatorParamMaps',\n",
       " 'getEvaluator',\n",
       " 'getOrDefault',\n",
       " 'getParam',\n",
       " 'getSeed',\n",
       " 'hasDefault',\n",
       " 'hasParam',\n",
       " 'isDefined',\n",
       " 'isSet',\n",
       " 'load',\n",
       " 'params',\n",
       " 'read',\n",
       " 'save',\n",
       " 'seed',\n",
       " 'set',\n",
       " 'setEstimator',\n",
       " 'setEstimatorParamMaps',\n",
       " 'setEvaluator',\n",
       " 'setSeed',\n",
       " 'subModels',\n",
       " 'transform',\n",
       " 'uid',\n",
       " 'write']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cv_rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:10:50.613051Z",
     "start_time": "2020-03-22T19:10:50.602055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8106176223201276,\n",
       " 0.8044321902562253,\n",
       " 0.8025702525429657,\n",
       " 0.829491736551097,\n",
       " 0.8219670917806259,\n",
       " 0.8034024734959226,\n",
       " 0.8155870376145662,\n",
       " 0.8180662175976634,\n",
       " 0.81007777035447,\n",
       " 0.8332143407541575,\n",
       " 0.7926130952316295,\n",
       " 0.8172692828597874,\n",
       " 0.815413940543019,\n",
       " 0.815413940543019,\n",
       " 0.8236515615130073,\n",
       " 0.8120970997802575,\n",
       " 0.8131841867250467,\n",
       " 0.829491736551097,\n",
       " 0.8240961423694948,\n",
       " 0.8303445788788958,\n",
       " 0.8123558512528858,\n",
       " 0.8285646538451237,\n",
       " 0.816374624590775,\n",
       " 0.836648714022421,\n",
       " 0.8218097356904649,\n",
       " 0.7977407046367286,\n",
       " 0.8218252347100499,\n",
       " 0.8183961601568988,\n",
       " 0.8233658771672054,\n",
       " 0.8318330274288643,\n",
       " 0.7986710075301835,\n",
       " 0.824874704986463,\n",
       " 0.829217769367822,\n",
       " 0.8207574829082216,\n",
       " 0.8341832533115061,\n",
       " 0.7962735066707687,\n",
       " 0.8058926802836588,\n",
       " 0.7879022766934174,\n",
       " 0.8287041495748881,\n",
       " 0.8303494444211224,\n",
       " 0.8038146273579008,\n",
       " 0.8193808370173861,\n",
       " 0.8048641495748883,\n",
       " 0.8257886948146709,\n",
       " 0.8229082355963935,\n",
       " 0.7981768464321646,\n",
       " 0.815939694095531,\n",
       " 0.8224027777544556,\n",
       " 0.8283970890736547,\n",
       " 0.8420933287932993,\n",
       " 0.7861676699537361,\n",
       " 0.7898203991044138,\n",
       " 0.8275186199467542,\n",
       " 0.8093279450985034,\n",
       " 0.8344490899691649,\n",
       " 0.7938193066346304,\n",
       " 0.8132674172953981,\n",
       " 0.8287041495748881,\n",
       " 0.8227631508288643,\n",
       " 0.8281048336647798,\n",
       " 0.8105971441690539,\n",
       " 0.8267474720659327,\n",
       " 0.8381121410776797,\n",
       " 0.8389061325515967,\n",
       " 0.8318381679911134,\n",
       " 0.7968979252860499,\n",
       " 0.8198007762072117,\n",
       " 0.8210493453047338,\n",
       " 0.8156437830194015,\n",
       " 0.8280362227808115,\n",
       " 0.7847270699083448,\n",
       " 0.8260371134503697,\n",
       " 0.8318381679911134,\n",
       " 0.8257886948146709,\n",
       " 0.8459998671680652,\n",
       " 0.8011839335953439,\n",
       " 0.8084552097277999,\n",
       " 0.818550061178378,\n",
       " 0.8431192487172274,\n",
       " 0.8195670877378611,\n",
       " 0.8038146273579008,\n",
       " 0.8193808370173861,\n",
       " 0.8074725438338721,\n",
       " 0.8214135218197378,\n",
       " 0.8185330626014604,\n",
       " 0.7981768464321646,\n",
       " 0.815939694095531,\n",
       " 0.8224027777544556,\n",
       " 0.8283970890736547,\n",
       " 0.8420933287932993,\n",
       " 0.7861676699537361,\n",
       " 0.7898203991044138,\n",
       " 0.823182059789962,\n",
       " 0.8093279450985034,\n",
       " 0.8293673196355335,\n",
       " 0.7938193066346304,\n",
       " 0.8132674172953981,\n",
       " 0.8287041495748881,\n",
       " 0.8227631508288643,\n",
       " 0.8281048336647798,\n",
       " 0.8064564112454031,\n",
       " 0.8267474720659327,\n",
       " 0.8381121410776797,\n",
       " 0.8389061325515967,\n",
       " 0.8347030643241486,\n",
       " 0.7974110980090574,\n",
       " 0.8198007762072117,\n",
       " 0.8236223792412567,\n",
       " 0.8156437830194015,\n",
       " 0.8305982456423381,\n",
       " 0.7872545220725322,\n",
       " 0.8260371134503697,\n",
       " 0.8276607420377771,\n",
       " 0.8257886948146709,\n",
       " 0.8459998671680652,\n",
       " 0.8011839335953439,\n",
       " 0.8084552097277999,\n",
       " 0.818550061178378,\n",
       " 0.8390840182454208,\n",
       " 0.8195670877378611,\n",
       " 0.8038146273579008,\n",
       " 0.8193808370173861,\n",
       " 0.8074725438338721,\n",
       " 0.8214135218197378,\n",
       " 0.8185330626014604,\n",
       " 0.7981768464321646,\n",
       " 0.815939694095531,\n",
       " 0.8224027777544556,\n",
       " 0.8283970890736547,\n",
       " 0.8420933287932993,\n",
       " 0.7861676699537361,\n",
       " 0.7898203991044138,\n",
       " 0.823182059789962,\n",
       " 0.8093279450985034,\n",
       " 0.8293673196355335,\n",
       " 0.7938193066346304,\n",
       " 0.8132674172953981,\n",
       " 0.8287041495748881,\n",
       " 0.8227631508288643,\n",
       " 0.8281048336647798,\n",
       " 0.8064564112454031,\n",
       " 0.8267474720659327,\n",
       " 0.8381121410776797,\n",
       " 0.8389061325515967,\n",
       " 0.8347030643241486,\n",
       " 0.7974110980090574,\n",
       " 0.8198007762072117,\n",
       " 0.8236223792412567,\n",
       " 0.8156437830194015,\n",
       " 0.8305982456423381,\n",
       " 0.7872545220725322,\n",
       " 0.8260371134503697,\n",
       " 0.8276607420377771,\n",
       " 0.8257886948146709,\n",
       " 0.8459998671680652,\n",
       " 0.8011839335953439,\n",
       " 0.8084552097277999,\n",
       " 0.818550061178378,\n",
       " 0.8390840182454208,\n",
       " 0.8195670877378611,\n",
       " 0.8038146273579008,\n",
       " 0.8193808370173861,\n",
       " 0.8074725438338721,\n",
       " 0.8214135218197378,\n",
       " 0.8185330626014604,\n",
       " 0.7981768464321646,\n",
       " 0.815939694095531,\n",
       " 0.8224027777544556,\n",
       " 0.8283970890736547,\n",
       " 0.8420933287932993,\n",
       " 0.7861676699537361,\n",
       " 0.7898203991044138,\n",
       " 0.823182059789962,\n",
       " 0.8093279450985034,\n",
       " 0.8293673196355335,\n",
       " 0.7938193066346304,\n",
       " 0.8132674172953981,\n",
       " 0.8287041495748881,\n",
       " 0.8227631508288643,\n",
       " 0.8281048336647798,\n",
       " 0.8064564112454031,\n",
       " 0.8267474720659327,\n",
       " 0.8381121410776797,\n",
       " 0.8389061325515967,\n",
       " 0.8347030643241486,\n",
       " 0.7974110980090574,\n",
       " 0.8198007762072117,\n",
       " 0.8236223792412567,\n",
       " 0.8156437830194015,\n",
       " 0.8305982456423381,\n",
       " 0.7872545220725322,\n",
       " 0.8260371134503697,\n",
       " 0.8276607420377771,\n",
       " 0.8257886948146709,\n",
       " 0.8459998671680652,\n",
       " 0.8011839335953439,\n",
       " 0.8084552097277999,\n",
       " 0.818550061178378,\n",
       " 0.8390840182454208,\n",
       " 0.8195670877378611]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rf_results.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:10:04.805358Z",
     "start_time": "2020-03-22T19:10:04.763180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8106176223201276,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8044321902562253,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8025702525429657,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.829491736551097,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8219670917806259,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8034024734959226,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8155870376145662,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8180662175976634,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.81007777035447,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8332143407541575,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7926130952316295,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8172692828597874,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.815413940543019,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.815413940543019,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8236515615130073,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8120970997802575,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8131841867250467,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.829491736551097,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8240961423694948,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8303445788788958,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8123558512528858,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8285646538451237,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.816374624590775,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.836648714022421,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8218097356904649,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7977407046367286,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8218252347100499,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8183961601568988,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8233658771672054,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8318330274288643,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7986710075301835,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.824874704986463,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.829217769367822,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8207574829082216,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8341832533115061,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7962735066707687,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8058926802836588,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.7879022766934174,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8287041495748881,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8303494444211224,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8038146273579008,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8193808370173861,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8048641495748883,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8257886948146709,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8229082355963935,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7981768464321646,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.815939694095531,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8224027777544556,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8283970890736547,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8420933287932993,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7861676699537361,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.7898203991044138,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8275186199467542,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8093279450985034,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8344490899691649,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7938193066346304,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8132674172953981,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8287041495748881,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8227631508288643,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8281048336647798,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8105971441690539,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8267474720659327,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8381121410776797,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8389061325515967,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8318381679911134,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7968979252860499,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8198007762072117,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8210493453047338,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8156437830194015,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8280362227808115,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7847270699083448,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8260371134503697,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8318381679911134,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8257886948146709,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8459998671680652,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8011839335953439,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8084552097277999,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.818550061178378,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8431192487172274,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8195670877378611,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8038146273579008,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8193808370173861,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8074725438338721,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8214135218197378,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8185330626014604,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7981768464321646,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.815939694095531,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8224027777544556,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8283970890736547,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8420933287932993,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7861676699537361,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.7898203991044138,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.823182059789962,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8093279450985034,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8293673196355335,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7938193066346304,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8132674172953981,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8287041495748881,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8227631508288643,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8281048336647798,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8064564112454031,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8267474720659327,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8381121410776797,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8389061325515967,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8347030643241486,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7974110980090574,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8198007762072117,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8236223792412567,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8156437830194015,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8305982456423381,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7872545220725322,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8260371134503697,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8276607420377771,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8257886948146709,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8459998671680652,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8011839335953439,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8084552097277999,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.818550061178378,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8390840182454208,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8195670877378611,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8038146273579008,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8193808370173861,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8074725438338721,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8214135218197378,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8185330626014604,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7981768464321646,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.815939694095531,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8224027777544556,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8283970890736547,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8420933287932993,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7861676699537361,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.7898203991044138,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.823182059789962,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8093279450985034,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8293673196355335,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7938193066346304,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8132674172953981,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8287041495748881,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8227631508288643,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8281048336647798,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8064564112454031,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8267474720659327,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8381121410776797,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8389061325515967,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8347030643241486,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7974110980090574,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8198007762072117,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8236223792412567,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8156437830194015,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8305982456423381,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7872545220725322,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8260371134503697,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8276607420377771,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8257886948146709,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8459998671680652,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8011839335953439,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8084552097277999,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.818550061178378,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8390840182454208,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8195670877378611,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8038146273579008,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8193808370173861,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8074725438338721,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8214135218197378,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8185330626014604,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 5,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7981768464321646,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.815939694095531,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8224027777544556,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8283970890736547,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8420933287932993,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7861676699537361,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.7898203991044138,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.823182059789962,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8093279450985034,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8293673196355335,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 15,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7938193066346304,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8132674172953981,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8287041495748881,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8227631508288643,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8281048336647798,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 20,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8064564112454031,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8267474720659327,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8381121410776797,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8389061325515967,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8347030643241486,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7974110980090574,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8198007762072117,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8236223792412567,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8156437830194015,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8305982456423381,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 30,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.7872545220725322,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8260371134503697,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.8276607420377771,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8257886948146709,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8459998671680652,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 35,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70}),\n",
       " (0.8011839335953439,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 10}),\n",
       " (0.8084552097277999,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.818550061178378,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.8390840182454208,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 60}),\n",
       " (0.8195670877378611,\n",
       "  {Param(parent='RandomForestClassifier_f4ca53297116', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 25,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='RandomForestClassifier_f4ca53297116', name='numTrees', doc='Number of trees to train (>= 1).'): 70})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(cv_rf_results.getEstimatorParamMaps())\n",
    "\n",
    "list(zip(cv_rf_results.avgMetrics, cv_rf_results.getEstimatorParamMaps()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T03:52:21.429764Z",
     "start_time": "2020-03-22T03:08:58.813753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to train: 200\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o265827.transform.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 18510.0 failed 1 times, most recent failure: Lost task 11.0 in stage 18510.0 (TID 1531258, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:366)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:366)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:271)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:339)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3384)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3365)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2552)\n\tat org.apache.spark.sql.Dataset.first(Dataset.scala:2559)\n\tat org.apache.spark.ml.feature.VectorAssembler$.getVectorLengthsFromFirstRow(VectorAssembler.scala:200)\n\tat org.apache.spark.ml.feature.VectorAssembler$.getLengths(VectorAssembler.scala:226)\n\tat org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:96)\n\tat sun.reflect.GeneratedMethodAccessor137.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0ecbe8215b21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_random_forest_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcv_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv_rf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mbestIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mbestModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCrossValidatorModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o265827.transform.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 18510.0 failed 1 times, most recent failure: Lost task 11.0 in stage 18510.0 (TID 1531258, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n\tat org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:366)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:366)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:271)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:339)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3384)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3365)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2552)\n\tat org.apache.spark.sql.Dataset.first(Dataset.scala:2559)\n\tat org.apache.spark.ml.feature.VectorAssembler$.getVectorLengthsFromFirstRow(VectorAssembler.scala:200)\n\tat org.apache.spark.ml.feature.VectorAssembler$.getLengths(VectorAssembler.scala:226)\n\tat org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:96)\n\tat sun.reflect.GeneratedMethodAccessor137.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n"
     ]
    }
   ],
   "source": [
    "pipeline = create_random_forest_pipeline()\n",
    "cv_rf = random_forest_grid_search(pipeline)\n",
    "cv_rf_results = cv_rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T17:10:35.987456Z",
     "start_time": "2020-03-22T17:10:10.484596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16 15]\n",
      " [ 5 96]]\n"
     ]
    }
   ],
   "source": [
    "predictions = cv_rf_results.bestModel.transform(test_df)\n",
    "\n",
    "df_results = predictions.select(['canceled', 'prediction']).toPandas()\n",
    "df_results['prediction'] = df_results.prediction.apply(int)\n",
    "\n",
    "plot_confusion_matrix(df_results['canceled'], df_results['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T17:27:25.837073Z",
     "start_time": "2020-03-22T17:27:25.831381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rf_results.bestModel.stages[-1].numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol = 'idx_labels', featuresCol = 'features', numTrees = 10)\n",
    "dir(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T17:11:17.409191Z",
     "start_time": "2020-03-22T17:11:17.403489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_85311fec7e03"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rf_results.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T22:43:55.011960Z",
     "start_time": "2020-03-21T22:43:45.931376Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T22:44:06.060150Z",
     "start_time": "2020-03-21T22:43:56.785468Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T22:11:05.946121Z",
     "start_time": "2020-03-21T22:10:56.684420Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results = predictions.select(['canceled', 'prediction']).toPandas()\n",
    "df_results['prediction'] = df_results.prediction.apply(int)\n",
    "plot_confusion_matrix(df_results['canceled'], df_results['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T22:07:09.309168Z",
     "start_time": "2020-03-21T22:07:09.304265Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol = 'canc', metricName = 'areaUnderROC')\n",
    " \n",
    "best_model_results = cv_gbt_results.bestModel.transform(test_df)\n",
    "    \n",
    "evaluator.evaluate(best_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T15:02:01.341210Z",
     "start_time": "2020-03-01T15:02:01.298441Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = create_gradient_boost_pipeline()\n",
    "cv_gbt = gradient_boost_grid_search(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T18:08:34.371481Z",
     "start_time": "2020-03-01T15:02:03.210992Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_gbt_results = cv_gbt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:06:39.482836Z",
     "start_time": "2020-03-01T14:06:39.477907Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_gbt_results.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:06:56.517560Z",
     "start_time": "2020-03-01T14:06:56.488834Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = cv_gbt_results.avgMetrics\n",
    "params = [{p.name: v for p, v in m.items()} for m in cv_gbt.getEstimatorParamMaps()]\n",
    "params_pd = pd.DataFrame(params)\n",
    "params_pd['score'] = scores\n",
    "params_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T03:00:50.268594Z",
     "start_time": "2020-03-01T03:00:44.103376Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol = 'canc', metricName = 'areaUnderROC')\n",
    " \n",
    "best_model_results = cv_gbt_results.bestModel.transform(test_df)\n",
    "    \n",
    "evaluator.evaluate(best_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:35:59.822421Z",
     "start_time": "2020-03-21T23:35:39.991922Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluator = BinaryClassificationEvaluator(labelCol = 'canceled', metricName = 'f1Measure')\n",
    "\n",
    "metrics_to_evaluate = [ 'accuracy', 'f1', 'weightedPrecision', 'weightedRecall' ]\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'canceled', metricName = 'f1')\n",
    " \n",
    "best_model_results = cv_rf_results.bestModel.transform(test_df)\n",
    "    \n",
    "evaluator.evaluate(best_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T03:01:23.359069Z",
     "start_time": "2020-03-01T03:01:19.905831Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_multiclass_classifier(best_model_results, ('canc', 'prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T00:39:49.645897Z",
     "start_time": "2020-03-01T00:38:10.913242Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_multiclass_classifier(best_model_results, ('canc', 'prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T00:13:53.940084Z",
     "start_time": "2020-03-01T00:13:40.288881Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model_results.select(['features', 'prediction', 'canc']).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T22:56:07.000157Z",
     "start_time": "2020-02-29T22:55:53.705530Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model_results.select(['rawPrediction', 'prediction', 'canc']).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T21:06:14.995253Z",
     "start_time": "2020-02-29T21:05:57.745177Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.filter('canc = 1').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T21:06:44.651611Z",
     "start_time": "2020-02-29T21:06:27.509694Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.filter('canc = 1').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T03:01:53.168730Z",
     "start_time": "2020-03-01T03:01:52.310500Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model_results.select(\"prediction\", \"canc\", \"features\").filter('canc = 1').groupby(['canc', 'prediction']).agg({'canc':'count'}).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T00:47:05.176261Z",
     "start_time": "2020-03-01T00:47:05.169056Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_rf_results.bestModel.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps\n",
    "Clean up your code, adding comments and renaming variables to make the code easier to read and maintain. Refer to the Spark Project Overview page and Data Scientist Capstone Project Rubric to make sure you are including all components of the capstone project and meet all expectations. Remember, this includes thorough documentation in a README file in a Github repository, as well as a web app or blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
